{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boxey as bx\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "from boxey import Process, Input, Model\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import random\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import Problem, UniformBounded\n",
    "from sampler import MCMCSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the names of the compartments\n",
    "compartments = ['soil_prec', 'soil_pfsa', 'gw_prec', 'gw_pfsa']\n",
    "\n",
    "def get_model(scenario, training_volume, fire_volume, R_soil_prec, R_soil_pfsa, R_gw_prec, R_gw_pfsa, k_bio):\n",
    "    \n",
    "    with open(f'data_and_constraints/{scenario}.yaml', 'r') as stream:\n",
    "        data = yaml.safe_load(stream)\n",
    "\n",
    "    k_soil = data['k_soil']\n",
    "    k_gw = data['k_gw']\n",
    "    \n",
    "    c_prec = data['c_prec']\n",
    "    c_pfsa = data['c_pfsa']\n",
    "\n",
    "    # List the processes to represent.\n",
    "    # Process needs: (name, timescale, compartment of origin, destination compartment)\n",
    "    processes = [ Process('soil2gw_prec', R_soil_prec/k_soil, 'soil_prec', 'gw_prec'),\n",
    "                Process('soil2gw_pfsa', R_soil_pfsa/k_soil, 'soil_pfsa', 'gw_pfsa'),\n",
    "                Process('soil_prec2pfsa', 1/k_bio, 'soil_prec', 'soil_pfsa'),\n",
    "                Process('gw_prec2pfsa', 1/k_bio, 'gw_prec', 'gw_pfsa'),\n",
    "                Process('gw_prec', R_gw_prec/k_gw, 'gw_prec', None),\n",
    "                Process('gw_pfsa', R_gw_pfsa/k_gw, 'gw_pfsa', None),\n",
    "            \n",
    "            ]\n",
    "\n",
    "    # List the inputs to use. \n",
    "    # in the 0 inputs bookending these make it go from e.g. 0 at exactly 1970 to c_prec*V a tiny time later\n",
    "    inputs = [ Input('AFFF_training_prec', [0., c_prec * training_volume, c_prec * training_volume, 0.], [1970.0, 1970.001, 1985.999, 1986.0], 'soil_prec'),\n",
    "            Input('AFFF_training_pfsa', [0., c_pfsa * training_volume, c_pfsa * training_volume, 0.], [1970.0, 1970.001, 1985.999, 1986.0], 'soil_pfsa'),\n",
    "            Input('AFFF_fire_prec', [0., c_prec * fire_volume, c_prec * fire_volume, 0.], [1997.0, 1997.001, 1997.999, 1998.0], 'soil_prec'),\n",
    "            Input('AFFF_fire_pfsa', [0., c_pfsa * fire_volume, c_pfsa * fire_volume, 0.], [1997.0, 1997.001, 1997.999, 1998.0], 'soil_pfsa'),]\n",
    "\n",
    "    model = bx.create_model(compartments, processes)\n",
    "    model = bx.add_inputs(model, inputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AFFF_use_history(scenario, yearly_training_volume, fire_volume, R_soil_prec, R_soil_pfsa, R_gw_prec, R_gw_pfsa, k_bio,\n",
    "                    time_points=None):\n",
    "    \"\"\"To make iterating easier for optimizing.\"\"\"\n",
    "    model = get_model(scenario, training_volume = yearly_training_volume, fire_volume = fire_volume,\n",
    "                      R_soil_prec = R_soil_prec,\n",
    "                      R_soil_pfsa = R_soil_pfsa, \n",
    "                      R_gw_prec = R_gw_prec,\n",
    "                      R_gw_pfsa = R_gw_pfsa,\n",
    "                      k_bio = k_bio)\n",
    "    if time_points is None:\n",
    "        tstart, tend = 1970, 2100\n",
    "        time_points = np.arange(tstart, tend, 1)\n",
    "        time_points_in = sorted(time_points)\n",
    "    else:\n",
    "        time_points_in = sorted(np.unique([1970]+list(time_points)))\n",
    "    reservoirs, times = model.run(time_points_in, initial_conditions=None)\n",
    "\n",
    "    gw_pfsa_reservoir = np.array([reservoirs[times.index(t),3] for t in time_points[:-1]])\n",
    "    gw_prec_reservoir = np.array([reservoirs[times.index(t),2] for t in time_points[:-1]])\n",
    "    gw_pfsa_prec_ratio = np.mean([ratio for ratio in gw_pfsa_reservoir / gw_prec_reservoir if np.isfinite(ratio)])\n",
    "\n",
    "    soil_pfsa_reservoir = reservoirs[-1, 1]\n",
    "    \n",
    "    return (gw_pfsa_reservoir, gw_pfsa_prec_ratio, soil_pfsa_reservoir)\n",
    "\n",
    "def AFFF_use_history_log(scenario, yearly_training_volume, fire_volume, R_soil_prec, R_soil_pfsa, R_gw_prec, R_gw_pfsa, k_bio,\n",
    "                    time_points=None):\n",
    "    \"\"\"To make iterating easier for optimizing.\"\"\"\n",
    "    return AFFF_use_history(scenario, 10**yearly_training_volume, 10**fire_volume, 10**R_soil_prec, 10**R_soil_pfsa,\n",
    "                            10**R_gw_prec, 10**R_gw_pfsa, 10**k_bio,\n",
    "                            time_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyPrior(UniformBounded):\n",
    "#     pass # just a bounded prior for now. Change as you wish\n",
    "\n",
    "class MyPrior():\n",
    "    \n",
    "    def __init__(self, prior_type, param_1, param_2):\n",
    "        self.prior_type = prior_type\n",
    "        self.param_1 = param_1\n",
    "        self.param_2 = param_2\n",
    "    \n",
    "    def uniform(self, proposal, idx):\n",
    "        if self.param_1[idx] <= proposal <= self.param_2[idx]:\n",
    "            return(0.)\n",
    "        else:\n",
    "            return(-1E6)\n",
    "    \n",
    "    def bounded_normal(self, proposal, idx):\n",
    "        if proposal >= 0.:\n",
    "            return(-0.5 * ((10**proposal - 10**self.param_1[idx]) / 10**self.param_2[idx])**2)\n",
    "        else:\n",
    "            return(-1E6)\n",
    "        \n",
    "    def __call__(self, proposal : ArrayLike) -> float:\n",
    "        \n",
    "        prior = [self.uniform(val, idx) if self.prior_type[idx] == 'U' else self.bounded_normal(val, idx) for idx, val in enumerate(proposal)]\n",
    "        return(np.sum(prior))\n",
    "\n",
    "class MyLikelihood:\n",
    "    def __init__(self, scenario):\n",
    "        self.scenario = scenario\n",
    "        with open(f'data_and_constraints/{scenario}.yaml', 'r') as stream:\n",
    "            data = yaml.safe_load(stream)\n",
    "\n",
    "        gw_year = np.array(data['gw_year'])\n",
    "        self.year = np.append(gw_year, data['soil_year'])\n",
    "        self.gw_pfsa_reservoir = data['gw_pfsa_reservoir']\n",
    "        self.log_soil_pfsa_reservoir = np.log10(data['soil_pfsa_reservoir'])\n",
    "        self.gw_pfsa_prec_ratio = np.array(data['gw_pfsa_prec_ratio'])\n",
    "        \n",
    "    def __call__(self, params):\n",
    "        modeled_gw_pfsa_reservoir, modeled_gw_pfsa_prec_ratio, modeled_soil_pfsa_reservoir = AFFF_use_history_log(\n",
    "            self.scenario,\n",
    "            params[0], params[1], params[2], params[3], params[4], params[5], params[6], time_points=self.year)\n",
    "        \n",
    "        #minimize the sum of squared errors for groundwater pfsa concentrations\n",
    "        #minimize the sum of squared errors for groundwater pfsa concentrations\n",
    "        likelihood = -np.sum((np.log10(self.gw_pfsa_reservoir) - np.log10(modeled_gw_pfsa_reservoir))**2)\n",
    "        \n",
    "        #penalize likelihood if soil pfsa reservoir proposal is more or less than one order of magnitude\n",
    "        #from measurement\n",
    "        if self.log_soil_pfsa_reservoir - 0.1 < np.log10(modeled_soil_pfsa_reservoir) < self.log_soil_pfsa_reservoir + 1:\n",
    "            likelihood += 0\n",
    "        else:\n",
    "            likelihood += -1E6\n",
    "            \n",
    "        #penalize likelihood if gw pfsa to precursor ratio is more or less than two standard deviations\n",
    "        #from measurements\n",
    "        if self.gw_pfsa_prec_ratio[0] - 2 * self.gw_pfsa_prec_ratio[1] < modeled_gw_pfsa_prec_ratio < self.gw_pfsa_prec_ratio[0] + 2 * self.gw_pfsa_prec_ratio[1]:\n",
    "            likelihood += 0\n",
    "        else:\n",
    "        \n",
    "            likelihood += -1E6\n",
    "        \n",
    "        #enforce Rrec > Rpfaa for given compartment\n",
    "        if params[2] > params[3]:\n",
    "            likelihood += 0\n",
    "        else:\n",
    "            likelihood += -1E6\n",
    "        \n",
    "        if params[4] > params[5]:\n",
    "            likelihood += 0\n",
    "        else:\n",
    "            likelihood += -1E6\n",
    "            \n",
    "        return(likelihood)\n",
    "\n",
    "class MyProblem(Problem):\n",
    "\n",
    "    def __init__(self, n_dimensions, lower_bounds, upper_bounds, scenario):\n",
    "        self.n_dimensions = n_dimensions\n",
    "        self.lower_bounds = np.array(lower_bounds)\n",
    "        self.upper_bounds = np.array(upper_bounds)\n",
    "        self.prior = MyPrior(prior_type = ['U', 'U', 'U', 'U', 'U', 'U', 'U'],\n",
    "            param_1=self.lower_bounds, param_2=self.upper_bounds)\n",
    "        self.likelihood = MyLikelihood(scenario)\n",
    "\n",
    "    def get_bounds(self):\n",
    "        return self.lower_bounds, self.upper_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fta_pfc(scenario):\n",
    "    with open(f'data_and_constraints/{scenario}.yaml', 'r') as stream:\n",
    "        data = yaml.safe_load(stream)\n",
    "        \n",
    "    yearly_training_volume = np.log10(np.array(data['V_training']))\n",
    "    fire_volume = np.log10(np.array(data['V_fire']))\n",
    "    R_soil_prec = np.log10(np.array(data['R_soil_prec']))\n",
    "    R_soil_pfsa = np.log10(np.array(data['R_soil_pfsa']))\n",
    "    R_gw_prec = np.log10(np.array(data['R_gw_prec']))\n",
    "    R_gw_pfsa = np.log10(np.array(data['R_gw_pfsa']))\n",
    "    k_bio = np.log10(np.array(data['k_bio']))\n",
    "    \n",
    "    problem = MyProblem(7,\n",
    "        [yearly_training_volume[0], fire_volume[0], R_soil_prec[0], R_soil_pfsa[0], R_gw_prec[0], R_gw_pfsa[0], k_bio[0]],\n",
    "        [yearly_training_volume[1], fire_volume[1], R_soil_prec[1], R_soil_pfsa[1], R_gw_prec[1], R_gw_pfsa[1], k_bio[1]],\n",
    "        scenario = scenario)\n",
    "\n",
    "    return(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = MCMCSampler(max_steps=100000, Nwalkers=4, Nincrement=500, target_effective_steps=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/0txmsx4s6yg188n7v90wwnfm0000gn/T/ipykernel_27393/1226582035.py:20: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  gw_pfsa_prec_ratio = np.mean([ratio for ratio in gw_pfsa_reservoir / gw_prec_reservoir if np.isfinite(ratio)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance rate is 0.58 when alpha is 0.3\n",
      "Sampling posterior in 500-iteration increments.\n",
      "After 500 iterations, autocorr time: unavailable\n",
      "After 1000 iterations, autocorr time: unavailable\n",
      "After 1500 iterations, autocorr time: unavailable\n",
      "After 2000 iterations, autocorr time: unavailable\n",
      "After 2500 iterations, autocorr time: unavailable\n",
      "After 3000 iterations, autocorr time: unavailable\n",
      "After 3500 iterations, autocorr time: unavailable\n",
      "After 4000 iterations, autocorr time: unavailable\n",
      "After 4500 iterations, autocorr time: unavailable\n",
      "After 5000 iterations, autocorr time: unavailable\n",
      "After 5500 iterations, autocorr time: unavailable\n",
      "After 6000 iterations, autocorr time: unavailable\n",
      "After 6500 iterations, autocorr time: unavailable\n",
      "After 7000 iterations, autocorr time: unavailable\n",
      "After 7500 iterations, autocorr time: unavailable\n",
      "After 8000 iterations, autocorr time: unavailable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/0txmsx4s6yg188n7v90wwnfm0000gn/T/ipykernel_27393/1226582035.py:20: RuntimeWarning: overflow encountered in true_divide\n",
      "  gw_pfsa_prec_ratio = np.mean([ratio for ratio in gw_pfsa_reservoir / gw_prec_reservoir if np.isfinite(ratio)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 8500 iterations, autocorr time: unavailable\n",
      "After 9000 iterations, autocorr time: unavailable\n",
      "After 9500 iterations, autocorr time: unavailable\n",
      "After 10000 iterations, autocorr time: unavailable\n",
      "After 10500 iterations, autocorr time: unavailable\n",
      "After 11000 iterations, autocorr time: 219.65043374715268\n",
      "After 11500 iterations, effective number of samples:                    1494\n",
      "After 12000 iterations, effective number of samples:                    1569\n",
      "After 12500 iterations, effective number of samples:                    1655\n",
      "After 13000 iterations, effective number of samples:                    1721\n",
      "After 13500 iterations, effective number of samples:                    1781\n",
      "After 14000 iterations, effective number of samples:                    1865\n",
      "After 14500 iterations, effective number of samples:                    1925\n",
      "After 15000 iterations, effective number of samples:                    2005\n",
      "After 15500 iterations, effective number of samples:                    2016\n",
      "After 16000 iterations, effective number of samples:                    2010\n",
      "WARNING: Number of independent samples decreasing!\n",
      "After 16500 iterations, effective number of samples:                    2055\n",
      "After 17000 iterations, effective number of samples:                    2138\n",
      "After 17500 iterations, effective number of samples:                    2228\n",
      "After 18000 iterations, effective number of samples:                    2315\n",
      "After 18500 iterations, effective number of samples:                    2378\n",
      "After 19000 iterations, effective number of samples:                    2462\n",
      "After 19500 iterations, effective number of samples:                    2545\n",
      "SAMPLE DONE\n"
     ]
    }
   ],
   "source": [
    "C8_pfsa = fta_pfc('C8_pfsa')\n",
    "C8_pfsa_posterior = sampler.sample(problem = C8_pfsa, alpha = 0.3)\n",
    "C8_pfsa_posterior_samples = 10**C8_pfsa_posterior.samples\n",
    "np.savetxt('posterior_samples/C8_pfsa_posterior.csv', C8_pfsa_posterior_samples, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C6_pfsa = fta_pfc('C6_pfsa')\n",
    "C6_pfsa_posterior = sampler.sample(problem = C6_pfsa, alpha = 0.4)\n",
    "C6_pfsa_posterior_samples = 10**C6_pfsa_posterior.samples\n",
    "np.savetxt('posterior_samples/C6_pfsa_posterior.csv', C6_pfsa_posterior_samples, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C4_pfsa = fta_pfc('C4_pfsa')\n",
    "C4_pfsa_posterior = sampler.sample(problem = C4_pfsa, alpha = 0.4)\n",
    "C4_pfsa_posterior_samples = 10**C4_pfsa_posterior.samples\n",
    "np.savetxt('posterior_samples/C4_pfsa_posterior.csv', C4_pfsa_posterior_samples, delimiter = ',')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b769cf52ee3fa389db03a729a2ae3b15ed2aa7779183d71c9e057955aa75ca6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
